
An existing grasp generation method is used in this work https://github.com/dougsm/ggcnn
However, it has been modified - Please refer to 'original_documentation' folder for documentation of the GGCNN as provided by its creators[1]

This README details the adaptions made for use with the planar grasping platform.

The following files have been added:
	- ggcnn-master/run.py				 - gives grasps from depth images, calibrates background 
	- ggcnn-master/ROSlink.py			 - allows communication with ROS usings sockets
	- ggcnn-master/models/ggcnn2_bn.py		 - derivative of GGCNN2 with addition of batchnormalization
	- cornell_background.txt, cornell_sample.txt,    - store images so that run.py can operate without access to the full Cornell dataset 
	  depth_background.txt, scale_factor.txt   

The following folders have been added:
	- pretrained_models				 - contains models trained using Google Colab
	- trained_models				 - contains pretrained models obtained from https://github.com/dougsm/ggcnn/releases/tag/v0.1 
	- cornell					 - location for the Cornell Grasping Dataset 

The following files have been modified:
	- ggcnn-master/train_ggcnn.py			 - OpenCV compatibility change, removed use of TensorboardX
	- ggcnn-master/utils/data/cornell_data.py	 - OpenCV compatibility change, changed to use floating depth images
        - ggcnn-master/utils/dataset_processing/image.py - OpenCV compatibility change 

_________________________________________________________________________________
## Installation

To avoid compatability issues the files contained in ggcnn-master are run in an Anaconda environment.
To create the environment 'gr', and install the required packages:

conda create --name gr python=3
conda activate gr

conda install -c anaconda python=3.7
conda install numpy
conda install pytorch=1.7.1 torchvision torchaudio cudatoolkit=10.1 -c pytorch
conda install matplotlib 
conda install scikit-image
conda install -c menpo opencv
pip install torchsummary
pip install pyrealsense

conda list 

- The packages should resolve to compatable versions:

python                    3.7.10
numpy                     1.19.2
matplotlib                3.3.4
pytorch                   1.7.1         
torchvision               0.8.2
torchaudio                0.7.2
cudatoolkit               10.1.243
scikit-image              0.18.1
opencv                    3.4.2
torchsummary              1.5.1

_________________________________________________________________________________
## To run

If the ROS installation is complete:

roslaunch scara_grasping cnn.launch

Alternatively:

source ~/anaconda3/etc/profile.d/conda.sh
conda activate gr
cd ~/Planar-Grasping-Platform/grasp_generation/ggcnn-master
python run.py

The text "Ready to generate grasp" indicates that the CNN is operational, and the program is waiting to recieve a depth image via sockets
_________________________________________________________________________________
## Local training and evaluation of models:

The original link for downloading the Cornell grasping dataset is dead, but it can be obtained from:
	https://www.kaggle.com/oneoneliu/cornell-grasp

The pointcloud files of the Cornell dataset will need to be converted to .tiffs (as described by the original_documentation):

source ~/anaconda3/etc/profile.d/conda.sh
conda activate gr
cd ~/Planar-Grasping-Platform/grasp_generation/ggcnn-master
python -m utils.dataset_processing.generate_cornell_depth /cornell

python eval_ggcnn.py --network pretrained_models/epoch_50_cornell --dataset cornell --dataset-path  /cornell --iou-eval
python train_ggcnn.py --description example --network ggcnn2 --dataset cornell  --dataset-path /cornell


References:

[1]	title={{Closing the Loop for Robotic Grasping: A Real-time, Generative Grasp Synthesis Approach}},
	author={Morrison, Douglas and Corke, Peter and Leitner, J\"urgen},
	booktitle={Proc.\ of Robotics: Science and Systems (RSS)},
	year={2018}


